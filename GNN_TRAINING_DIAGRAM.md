# GNN Training Process Diagram

## High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHYLOGENETIC TREE SEARCH                      â”‚
â”‚                     WITH GNN Q-LEARNING                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Detailed Training Flow

```
EPISODE START
     â”‚
     â”œâ”€â–º [1] ENVIRONMENT RESET (~500ms)
     â”‚    â”œâ”€ Sample random tree from dataset
     â”‚    â”œâ”€ Extract graph structure:
     â”‚    â”‚   â€¢ Node features: [is_leaf] (1-dim per node)
     â”‚    â”‚   â€¢ Edge features: [branch_length] (1-dim per edge)
     â”‚    â”‚   â€¢ Edge index: bidirectional connections
     â”‚    â””â”€ Extract available SPR moves â†’ ActionEmbeddings
     â”‚         [4 node indices + 3 metadata floats = 7-dim per action]
     â”‚
     â”œâ”€â–º [2] EPISODE LOOP (20 steps per episode)
     â”‚    â”‚
     â”‚    â”œâ”€â–º [2a] ACTION SELECTION (~45ms)
     â”‚    â”‚    â”‚
     â”‚    â”‚    â”œâ”€ INPUT: GraphData + List[ActionEmbedding]
     â”‚    â”‚    â”‚
     â”‚    â”‚    â”œâ”€ TREE EMBEDDING CACHE CHECK:
     â”‚    â”‚    â”‚   â€¢ Cache key: (edge_index, node_features, edge_features)
     â”‚    â”‚    â”‚   â€¢ If cached: Return embedding instantly (~1ms)
     â”‚    â”‚    â”‚   â€¢ If miss: Compute GNN forward pass (~35ms)
     â”‚    â”‚    â”‚   â€¢ Cache hit rate: ~80-90% after warmup
     â”‚    â”‚    â”‚
     â”‚    â”‚    â”œâ”€ GNN FORWARD PASS (only on cache miss):
     â”‚    â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚    â”‚    â”‚   â”‚ Tree Encoding (encode_tree):         â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Node encoder: [1] â†’ [256]       â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ GAT Layer 1: message passing    â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ GAT Layer 2: message passing    â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ GAT Layer 3: message passing    â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Aggregation:                     â”‚
     â”‚    â”‚    â”‚   â”‚     - SUM pool   â†’ [256]            â”‚
     â”‚    â”‚    â”‚   â”‚     - MEAN pool  â†’ [256]            â”‚
     â”‚    â”‚    â”‚   â”‚     - MAX pool   â†’ [256]            â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Concat â†’ [768] tree embedding   â”‚
     â”‚    â”‚    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚    â”‚    â”‚   
     â”‚    â”‚   For EACH action:
     â”‚    â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚    â”‚    â”‚   â”‚ Action Tensor Cache:                 â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Convert ActionEmbedding â†’ tensor â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Cached by node indices          â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Reused across episodes          â”‚
     â”‚    â”‚    â”‚   â”‚ Action Encoding:                     â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Action encoder: [7] â†’ [256]     â”‚
     â”‚    â”‚    â”‚   â”‚ Q-Value Computation:                 â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Concat [tree:768 + action:256]  â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ MLP: [1024] â†’ [256] â†’ [256] â†’ [1]â”‚
     â”‚    â”‚    â”‚   â”‚   â€¢ Output: Q-value (scalar)         â”‚
     â”‚    â”‚    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚    â”‚    â”‚
     â”‚    â”‚    â”œâ”€ Compute Soft Q-values:
     â”‚    â”‚    â”‚   Q_soft = Î± * log(Î£ exp(Q_i / Î±))
     â”‚    â”‚    â”‚
     â”‚    â”‚    â””â”€ Sample action from softmax distribution
     â”‚    â”‚
     â”‚    â”œâ”€â–º [2b] ENVIRONMENT STEP (~25ms)
     â”‚    â”‚    â”œâ”€ Apply SPR move to tree
     â”‚    â”‚    â”œâ”€ Compute log-likelihood (reward)
     â”‚    â”‚    â””â”€ Extract next state (GraphData + actions)
     â”‚    â”‚
     â”‚    â”œâ”€â–º [2c] REPLAY BUFFER PUSH (~1ms)
     â”‚    â”‚    â””â”€ Store: (tree_graph, action, reward, 
     â”‚    â”‚              next_tree_graph, next_actions, done)
     â”‚    â”‚         All stored on GPU! (zero CPU transfers)
     â”‚    â”‚
     â”‚    â””â”€â–º [2d] AGENT UPDATE (~400ms) âœ… OPTIMIZED
     â”‚         â”‚   [Only if replay_buffer >= 1000 samples]
     â”‚         â”‚   [First update: ~700ms, after cache warmup: ~400ms]
     â”‚         â”‚
     â”‚         â”œâ”€ SAMPLE BATCH (128 transitions):
     â”‚         â”‚   â€¢ 128 tree graphs
     â”‚         â”‚   â€¢ 128 actions
     â”‚         â”‚   â€¢ 128 rewards
     â”‚         â”‚   â€¢ 128 next-state graphs
     â”‚         â”‚   â€¢ 128 next-action sets
     â”‚         â”‚
     â”‚         â”œâ”€ COMPUTE CURRENT Q-VALUES:
     â”‚         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚         â”‚   â”‚ Batch Operations (PARALLEL):           â”‚
     â”‚         â”‚   â”‚   1. Create batch graph (128 trees)    â”‚
     â”‚         â”‚   â”‚   2. Q1 encode: 128 trees â†’ [128, 768] â”‚
     â”‚         â”‚   â”‚   3. Q2 encode: 128 trees â†’ [128, 768] â”‚
     â”‚         â”‚   â”‚   4. Q1 actions: [128, 7] â†’ [128, 256] â”‚
     â”‚         â”‚   â”‚   5. Q2 actions: [128, 7] â†’ [128, 256] â”‚
     â”‚         â”‚   â”‚   6. Q1 heads: [128, 1024] â†’ [128]     â”‚
     â”‚         â”‚   â”‚   7. Q2 heads: [128, 1024] â†’ [128]     â”‚
     â”‚         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚         â”‚   Result: q1_vals[128], q2_vals[128]
     â”‚         â”‚
     â”‚         â”œâ”€ COMPUTE TARGET Q-VALUES:
     â”‚         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚         â”‚   â”‚ Next-State Processing (PARALLEL):      â”‚
     â”‚         â”‚   â”‚   1. Batch 128 next-state trees        â”‚
     â”‚         â”‚   â”‚   2. Target encode: [128, 768]         â”‚
     â”‚         â”‚   â”‚   3. Expand for actions:               â”‚
     â”‚         â”‚   â”‚      [128, N_actions, 768]             â”‚
     â”‚         â”‚   â”‚   4. Flatten: [128*N, 768]             â”‚
     â”‚         â”‚   â”‚   5. Encode all actions: [128*N, 256]  â”‚
     â”‚         â”‚   â”‚   6. Q-heads: [128*N] Q-values         â”‚
     â”‚         â”‚   â”‚   7. Reshape: [128, N_actions]         â”‚
     â”‚         â”‚   â”‚   8. Min(Q1, Q2) per state             â”‚
     â”‚         â”‚   â”‚   9. Soft-max value per state          â”‚
     â”‚         â”‚   â”‚  10. TD targets: r + Î³ * V_soft        â”‚
     â”‚         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚         â”‚   Result: q_targets[128]
     â”‚         â”‚
     â”‚         â”œâ”€ COMPUTE TD ERRORS:
     â”‚         â”‚   â€¢ td_error1 = q_targets - q1_vals
     â”‚         â”‚   â€¢ td_error2 = q_targets - q2_vals
     â”‚         â”‚
     â”‚         â”œâ”€ UPDATE Q-NETWORKS:
     â”‚         â”‚   â€¢ loss1 = mean(weights * td_error1Â²)
     â”‚         â”‚   â€¢ loss2 = mean(weights * td_error2Â²)
     â”‚         â”‚   â€¢ Backward pass through GNN
     â”‚         â”‚   â€¢ Optimizer step (Adam)
     â”‚         â”‚
     â”‚         â”œâ”€ UPDATE TEMPERATURE (Î±):
     â”‚         â”‚   â€¢ Compute policy entropy
     â”‚         â”‚   â€¢ Update log_Î± to match target entropy
     â”‚         â”‚
     â”‚         â”œâ”€ UPDATE REPLAY PRIORITIES:
     â”‚         â”‚   â€¢ new_prio = |td_error1| + |td_error2|
     â”‚         â”‚
     â”‚         â””â”€ SOFT UPDATE TARGET NETWORKS:
     â”‚             â€¢ target_Î¸ â† Ï„*Î¸ + (1-Ï„)*target_Î¸
     â”‚
     â””â”€â–º [3] EPISODE END
          â”œâ”€ Log metrics every 10 episodes
          â””â”€ Save checkpoint every 1000 episodes
```

## GNN Architecture Detail

```
TREE â†’ GRAPH NEURAL NETWORK â†’ TREE EMBEDDING
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT GRAPH                                      â”‚
â”‚   Nodes: [N, 1]  (is_leaf: 0.0 or 1.0)         â”‚
â”‚   Edges: [E, 1]  (branch_length: continuous)    â”‚
â”‚   Edge Index: [2, E]  (bidirectional pairs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NODE ENCODER                                     â”‚
â”‚   Linear: [1] â†’ [256]                           â”‚
â”‚   ReLU activation                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ [N, 256]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GAT LAYER 1 (4 attention heads)                 â”‚
â”‚   For each node:                                 â”‚
â”‚     - Gather messages from neighbors             â”‚
â”‚     - Weight by attention + edge features        â”‚
â”‚     - Aggregate with multi-head attention        â”‚
â”‚   Residual: x = ReLU(GAT(x)) + x               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ [N, 256]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GAT LAYER 2 (4 attention heads)                 â”‚
â”‚   Same structure as Layer 1                      â”‚
â”‚   Residual: x = ReLU(GAT(x)) + x               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ [N, 256]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GAT LAYER 3 (4 attention heads)                 â”‚
â”‚   Same structure as Layer 1                      â”‚
â”‚   Residual: x = ReLU(GAT(x)) + x               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ [N, 256]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GLOBAL POOLING (Information Preservation)       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ SUM:  Î£ node_features â†’ [256]  â”‚ Size-awareâ”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ MEAN: avg(node_features) â†’ [256]â”‚ Normalizedâ”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ MAX:  max(node_features) â†’ [256]â”‚ Extremes  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚   CONCATENATE â†’ [768]                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
TREE EMBEDDING [768]
```

## Q-Network Architecture

```
[TREE EMBEDDING: 768] + [ACTION EMBEDDING: 256]
           â†“
    CONCATENATE
           â†“
       [1024]
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Q-HEAD (3-layer MLP)â”‚
â”‚  Linear: [1024]â†’[256]â”‚
â”‚  ReLU + Dropout      â”‚
â”‚  Linear: [256]â†’[256] â”‚
â”‚  ReLU               â”‚
â”‚  Linear: [256]â†’[1]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    Q-VALUE (scalar)
```

## Memory Layout (80GB A100 GPU)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU MEMORY (80GB) - ACTUAL USAGE PER AGENT      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MODEL PARAMETERS (~50M params, ~800MB)          â”‚
â”‚   - GNN Q1 Network (4 GAT layers, hidden=256)   â”‚
â”‚   - GNN Q2 Network                               â”‚
â”‚   - Target Q1 Network                            â”‚
â”‚   - Target Q2 Network                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ REPLAY BUFFER (10,000 transitions, ~26MB)       â”‚
â”‚   - Tree graphs: 20K Ã— 708 bytes = 14MB         â”‚
â”‚   - Action embeddings with cached tensors: 10MB â”‚
â”‚   - Next action lists: ~2MB                      â”‚
â”‚   - Scalars (rewards, dones, priorities): <1MB  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TREE EMBEDDING CACHE (~30MB, grows over time)   â”‚
â”‚   - Cached GNN outputs: [768] per tree          â”‚
â”‚   - ~10,000 unique trees Ã— 3KB each             â”‚
â”‚   - Key: graph structure hash                    â”‚
â”‚   - 80-90% hit rate after warmup                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TRAINING BATCH (~100MB during update)           â”‚
â”‚   - 128 batched graphs                           â”‚
â”‚   - Tree embeddings [128, 768]                  â”‚
â”‚   - Action embeddings [128, 256]                â”‚
â”‚   - Gradients & optimizer states                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PYTORCH/CUDA OVERHEAD (~300MB)                  â”‚
â”‚   - CUDA context, allocator reserves            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL USED: ~1.2 GB per agent                   â”‚
â”‚ WITH 2 AGENTS: ~2.4 GB                          â”‚
â”‚ AVAILABLE: ~77.6 GB (97% free!)                 â”‚
â”‚                                                  â”‚
â”‚ ğŸ’¡ Could easily support:                        â”‚
â”‚   - replay_size=50,000 (130MB vs 26MB)         â”‚
â”‚   - hidden_dim=512 (4x model size)             â”‚
â”‚   - batch_size=512 (4x batch size)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Performance Breakdown

```
TIMING PER EPISODE (after caches warm up ~100 episodes):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Environment Reset:    ~30ms  (0.3%) â”‚
â”‚ Action Selection:     ~27ms  (3%)   â”‚ âœ… Tree embedding cache
â”‚ Environment Step:     ~31ms  (3%)   â”‚
â”‚ Replay Push:          ~1ms   (0%)   â”‚
â”‚ Agent Update:         ~400ms (94%)  â”‚ âœ… Action tensor cache + batching
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL PER STEP:       ~489ms        â”‚
â”‚ TOTAL PER EPISODE:    ~9.8s (20 steps with updates) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 30,000 EPISODES:      ~82 hours (~3.4 days) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OPTIMIZED UPDATE BREAKDOWN (400ms):
  - GNN tree encoding:       ~35% (140ms)
    * 4 GAT layers x 128 trees (batched)
    * Attention computation
    * Edge feature processing
    * Manual max pooling (torch-scatter avoided)
  
  - Action encoding/Q-heads:  ~25% (100ms)
    * Batch action encoding
    * Tensor cache hits: ~90%
    * MLP forward passes
  
  - Target computation:       ~25% (100ms)
    * Next-state processing
    * Soft-value computation
    * Fully batched operations
  
  - Backward pass/optimizer:  ~15% (60ms)
    * Gradient computation
    * Parameter updates

CACHE PERFORMANCE:
  - Tree embedding cache:
    * Warmup: First ~100 episodes
    * Hit rate: 80-90% after warmup
    * Saves: ~30ms per action selection
  
  - Action tensor cache:
    * Stored in ActionEmbedding objects
    * Hit rate: 90%+ from replay buffer reuse
    * Saves: ~2.5s per update initially
```

## Key Optimizations Applied

```
âœ… BATCHED OPERATIONS:
   - All 128 tree graphs encoded in parallel
   - All actions processed simultaneously
   - Full GPU storage (zero CPU transfers)
   - Separate Q1/Q2 action encoders (prevents graph sharing bug)

âœ… INFORMATION PRESERVATION:
   - Triple pooling (sum + mean + max)
   - No hand-crafted features
   - Bidirectional edges for unrooted trees
   - Residual connections in GAT layers

âœ… TREE EMBEDDING CACHE:
   - Caches GNN forward pass outputs (4 GAT layers)
   - Key: (edge_index, node_features, edge_features)
   - Stored on GPU in agent.tree_embedding_cache
   - 80-90% hit rate after warmup
   - Saves ~30ms per action selection
   - Memory: ~30MB for 10K unique trees

âœ… ACTION TENSOR CACHE:
   - Caches converted action tensors in ActionEmbedding objects
   - Key: (4 node indices, device)
   - Persists across episodes via replay buffer
   - 90%+ hit rate from replay reuse
   - Saves ~2.5s per update (2560 conversions â†’ instant lookups)
   - Memory: ~10MB for 10K actions

âœ… MANUAL MAX POOLING:
   - Replaced global_max_pool to avoid torch-scatter dependency
   - Prevents slow CPU fallback
   - Simple loop over batch dimension

ğŸ“Š PERFORMANCE GAINS:
   - Action selection: 39ms â†’ 27ms (30% faster)
   - Agent update: 3300ms â†’ 400ms (8x faster!)
   - Episode time: ~66s â†’ ~9.8s (6.7x faster!)
   - 30K training: 23 days â†’ 3.4 days (feasible!)
```

## Comparison: Hand-Crafted vs GNN

```
HAND-CRAFTED FEATURES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tree â†’ 50+ statistics   â”‚
â”‚ â”œâ”€ num_leaves           â”‚
â”‚ â”œâ”€ avg_branch_length    â”‚
â”‚ â”œâ”€ tree_depth           â”‚
â”‚ â””â”€ ... 47 more          â”‚
â”‚ â†’ Fixed [50] vector     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
Human-designed features
Structure information LOST

GNN FEATURES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tree â†’ Raw graph        â”‚
â”‚ â”œâ”€ node: [is_leaf]      â”‚
â”‚ â”œâ”€ edge: [branch_len]   â”‚
â”‚ â””â”€ topology preserved   â”‚
â”‚ â†’ Learned [768] vector  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
Learned representation
Structure information PRESERVED
```
